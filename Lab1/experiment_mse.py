"""
–≠–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç—ã —Å —É–≤–µ–ª–∏—á–µ–Ω–∏–µ–º MSE
–†–∞–∑–ª–∏—á–Ω—ã–µ —Å–ø–æ—Å–æ–±—ã –∫–æ–Ω—Ç—Ä–æ–ª–∏—Ä—É–µ–º–æ–≥–æ —É—Ö—É–¥—à–µ–Ω–∏—è –∫–∞—á–µ—Å—Ç–≤–∞ –º–æ–¥–µ–ª–∏
"""

import numpy as np
import pandas as pd
from preprocessing import preprocess_data
from feature_engineering import improve_preprocessing
from normalization import Normalizer
from linear_regression import LinearRegressionCustom
from sklearn.model_selection import train_test_split
from metrics import mse


def experiment_baseline(X, y):
    """Baseline - —á–∏—Å—Ç—ã–µ –¥–∞–Ω–Ω—ã–µ"""
    X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)
    normalizer = Normalizer(method='z-score')
    X_train_norm = normalizer.fit_transform(X_train)
    X_val_norm = normalizer.transform(X_val)
    
    model = LinearRegressionCustom(method='analytical')
    model.fit(X_train_norm, y_train)
    y_pred = model.predict(X_val_norm)
    return mse(y_val, y_pred)


def experiment_noise_y(X, y, noise_sigma=10.0):
    """–°–ø–æ—Å–æ–± 1: –®—É–º –≤ —Ü–µ–ª–µ–≤–æ–π –ø–µ—Ä–µ–º–µ–Ω–Ω–æ–π"""
    y_noisy = y + np.random.normal(0, noise_sigma, size=y.shape)
    X_train, X_val, y_train, y_val = train_test_split(X, y_noisy, test_size=0.2, random_state=42)
    normalizer = Normalizer(method='z-score')
    X_train_norm = normalizer.fit_transform(X_train)
    X_val_norm = normalizer.transform(X_val)
    
    model = LinearRegressionCustom(method='analytical')
    model.fit(X_train_norm, y_train)
    y_pred = model.predict(X_val_norm)
    return mse(y_val, y_pred)


def experiment_noise_X(X, y, noise_factor=0.5):
    """–°–ø–æ—Å–æ–± 2: –®—É–º –≤ –ø—Ä–∏–∑–Ω–∞–∫–∞—Ö (–≠–§–§–ï–ö–¢–ò–í–ù–û)"""
    X_noisy = X + np.random.normal(0, noise_factor, size=X.shape) * X.std(axis=0)
    X_train, X_val, y_train, y_val = train_test_split(X_noisy, y, test_size=0.2, random_state=42)
    normalizer = Normalizer(method='z-score')
    X_train_norm = normalizer.fit_transform(X_train)
    X_val_norm = normalizer.transform(X_val)
    
    model = LinearRegressionCustom(method='analytical')
    model.fit(X_train_norm, y_train)
    y_pred = model.predict(X_val_norm)
    return mse(y_val, y_pred)


def experiment_shuffle_y(X, y, shuffle_ratio=0.3):
    """–°–ø–æ—Å–æ–± 3: –ü–µ—Ä–µ–º–µ—à–∏–≤–∞–Ω–∏–µ —á–∞—Å—Ç–∏ y"""
    y_shuffled = y.copy()
    n_shuffle = int(shuffle_ratio * len(y))
    idx = np.random.choice(len(y), size=n_shuffle, replace=False)
    y_shuffled[idx] = np.random.permutation(y_shuffled[idx])
    
    X_train, X_val, y_train, y_val = train_test_split(X, y_shuffled, test_size=0.2, random_state=42)
    normalizer = Normalizer(method='z-score')
    X_train_norm = normalizer.fit_transform(X_train)
    X_val_norm = normalizer.transform(X_val)
    
    model = LinearRegressionCustom(method='analytical')
    model.fit(X_train_norm, y_train)
    y_pred = model.predict(X_val_norm)
    return mse(y_val, y_pred)


def experiment_few_features(X, y, n_features=3):
    """–°–ø–æ—Å–æ–± 4: –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –º–∞–ª–æ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤"""
    X_reduced = X[:, :n_features]
    X_train, X_val, y_train, y_val = train_test_split(X_reduced, y, test_size=0.2, random_state=42)
    normalizer = Normalizer(method='z-score')
    X_train_norm = normalizer.fit_transform(X_train)
    X_val_norm = normalizer.transform(X_val)
    
    model = LinearRegressionCustom(method='analytical')
    model.fit(X_train_norm, y_train)
    y_pred = model.predict(X_val_norm)
    return mse(y_val, y_pred)


def experiment_bad_gd(X, y):
    """–°–ø–æ—Å–æ–± 5: –ü–ª–æ—Ö–∏–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –≥—Ä–∞–¥–∏–µ–Ω—Ç–Ω–æ–≥–æ —Å–ø—É—Å–∫–∞"""
    X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)
    normalizer = Normalizer(method='z-score')
    X_train_norm = normalizer.fit_transform(X_train)
    X_val_norm = normalizer.transform(X_val)
    
    model = LinearRegressionCustom(method='gradient_descent', learning_rate=1e-6, n_iterations=5)
    model.fit(X_train_norm, y_train)
    y_pred = model.predict(X_val_norm)
    return mse(y_val, y_pred)


def experiment_zero_weights(X, y):
    """–°–ø–æ—Å–æ–± 6: –û–±–Ω—É–ª–∏—Ç—å –≤–µ—Å–∞ –ø–æ—Å–ª–µ –æ–±—É—á–µ–Ω–∏—è"""
    X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)
    normalizer = Normalizer(method='z-score')
    X_train_norm = normalizer.fit_transform(X_train)
    X_val_norm = normalizer.transform(X_val)
    
    model = LinearRegressionCustom(method='analytical')
    model.fit(X_train_norm, y_train)
    model.weights[:] = 0
    model.bias = np.mean(y_train)
    y_pred = model.predict(X_val_norm)
    return mse(y_val, y_pred)


def main():
    print("="*70)
    print("–≠–ö–°–ü–ï–†–ò–ú–ï–ù–¢–´ –° –£–í–ï–õ–ò–ß–ï–ù–ò–ï–ú MSE")
    print("="*70)
    
    # –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö
    train_df = pd.read_csv('train.csv')
    test_df = pd.read_csv('test.csv')
    
    from eda import perform_eda
    _, train_clean = perform_eda(train_df, save_plots=False)
    X, y, _, _ = improve_preprocessing(train_clean, None)
    
    np.random.seed(42)
    
    print(f"\n–ò—Å—Ö–æ–¥–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ:")
    print(f"  X shape: {X.shape}")
    print(f"  y mean: {y.mean():.2f}, std: {y.std():.2f}")
    
    # –≠–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç—ã
    results = []
    
    print("\n" + "="*70)
    print("–ó–ê–ü–£–°–ö –≠–ö–°–ü–ï–†–ò–ú–ï–ù–¢–û–í")
    print("="*70)
    
    mse_baseline = experiment_baseline(X, y)
    results.append(("Baseline (—á–∏—Å—Ç—ã–µ –¥–∞–Ω–Ω—ã–µ)", mse_baseline, 1.0))
    print(f"\n‚úì Baseline MSE: {mse_baseline:.4f}")
    
    mse_noise_y = experiment_noise_y(X, y, noise_sigma=10.0)
    results.append(("–®—É–º –≤ y (œÉ=10)", mse_noise_y, mse_noise_y/mse_baseline))
    print(f"‚úì –®—É–º –≤ y: {mse_noise_y:.4f} (√ó{mse_noise_y/mse_baseline:.2f})")
    
    mse_noise_X = experiment_noise_X(X, y, noise_factor=0.5)
    results.append(("–®—É–º –≤ X (factor=0.5)", mse_noise_X, mse_noise_X/mse_baseline))
    print(f"‚úì –®—É–º –≤ X: {mse_noise_X:.4f} (√ó{mse_noise_X/mse_baseline:.2f})")
    
    mse_shuffle = experiment_shuffle_y(X, y, shuffle_ratio=0.3)
    results.append(("–ü–µ—Ä–µ–º–µ—à–∞—Ç—å 30% y", mse_shuffle, mse_shuffle/mse_baseline))
    print(f"‚úì –ü–µ—Ä–µ–º–µ—à–∏–≤–∞–Ω–∏–µ y: {mse_shuffle:.4f} (√ó{mse_shuffle/mse_baseline:.2f})")
    
    mse_few = experiment_few_features(X, y, n_features=3)
    results.append(("–¢–æ–ª—å–∫–æ 3 –ø—Ä–∏–∑–Ω–∞–∫–∞", mse_few, mse_few/mse_baseline))
    print(f"‚úì –ú–∞–ª–æ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤: {mse_few:.4f} (√ó{mse_few/mse_baseline:.2f})")
    
    mse_bad_gd = experiment_bad_gd(X, y)
    results.append(("–ü–ª–æ—Ö–æ–π GD (lr=1e-6, iter=5)", mse_bad_gd, mse_bad_gd/mse_baseline))
    print(f"‚úì –ü–ª–æ—Ö–æ–π GD: {mse_bad_gd:.4f} (√ó{mse_bad_gd/mse_baseline:.2f})")
    
    mse_zero = experiment_zero_weights(X, y)
    results.append(("–ù—É–ª–µ–≤—ã–µ –≤–µ—Å–∞", mse_zero, mse_zero/mse_baseline))
    print(f"‚úì –ù—É–ª–µ–≤—ã–µ –≤–µ—Å–∞: {mse_zero:.4f} (√ó{mse_zero/mse_baseline:.2f})")
    
    # –ò—Ç–æ–≥–æ–≤–∞—è —Ç–∞–±–ª–∏—Ü–∞
    print("\n" + "="*70)
    print("–ò–¢–û–ì–û–í–ê–Ø –¢–ê–ë–õ–ò–¶–ê")
    print("="*70)
    print(f"{'–ú–µ—Ç–æ–¥':<35} {'MSE':<15} {'–ü—Ä–∏—Ä–æ—Å—Ç':<10}")
    print("-"*70)
    for name, mse_val, ratio in results:
        print(f"{name:<35} {mse_val:<15.4f} √ó{ratio:<9.2f}")
    print("="*70)
    
    # –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏
    print("\nüìä –†–ï–ö–û–ú–ï–ù–î–ê–¶–ò–ò:")
    print("  üî• –î–ª—è —É–º–µ—Ä–µ–Ω–Ω–æ–≥–æ —Ä–æ—Å—Ç–∞ MSE (√ó1.5-2): —à—É–º –≤ X –∏–ª–∏ –ø–µ—Ä–µ–º–µ—à–∏–≤–∞–Ω–∏–µ y")
    print("  üî• –î–ª—è —Å–∏–ª—å–Ω–æ–≥–æ —Ä–æ—Å—Ç–∞ MSE (√ó3-5): –º–∞–ª–æ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –∏–ª–∏ –ø–ª–æ—Ö–æ–π GD")
    print("  üî• –î–ª—è —ç–∫—Å—Ç—Ä–µ–º–∞–ª—å–Ω–æ–≥–æ —Ä–æ—Å—Ç–∞ (√ó10+): –Ω—É–ª–µ–≤—ã–µ –≤–µ—Å–∞")


if __name__ == "__main__":
    main()
